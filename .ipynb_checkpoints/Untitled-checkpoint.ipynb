{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/spencergordon/anaconda/envs/tensorflow/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt('training_data.txt', skiprows=1)\n",
    "y = data[:, 0]\n",
    "X = data[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(dropout_prob=0.5):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1000, activation='relu', input_dim=(1000)))\n",
    "    model.add(Dropout(dropout_prob))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dropout(dropout_prob))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(dropout_prob))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "def cross_validate(dropout_prob):\n",
    "    accuracies = []\n",
    "    print('Cross-validating with dropout_prob {}'.format(dropout_prob))\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    for ix, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        X_train, X_test = X[train_index,:], X[test_index,:]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model = build_model(dropout_prob)\n",
    "        print('\\t\\ttraining fold {} with dropout_prob {}: '.format(ix, dropout_prob), end='', flush=True)\n",
    "        model.fit(X_train, y_train, epochs=20, batch_size=64, verbose=0)\n",
    "        score = model.evaluate(X_test, y_test, batch_size=64, verbose=0)\n",
    "        accuracies.append(score[1])\n",
    "        print('accuracy={}'.format(accuracies[-1]))\n",
    "    print('\\tAverage accuracy of {}'.format(sum(accuracies)/len(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = build_model(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validating with dropout_prob 0.1\n",
      "\t\ttraining fold 0 with dropout_prob 0.1: accuracy=0.82875\n",
      "\t\ttraining fold 1 with dropout_prob 0.1: accuracy=0.83025\n",
      "\t\ttraining fold 2 with dropout_prob 0.1: accuracy=0.8295\n",
      "\t\ttraining fold 3 with dropout_prob 0.1: accuracy=0.828\n",
      "\t\ttraining fold 4 with dropout_prob 0.1: accuracy=0.832\n",
      "\tAverage accuracy of 0.8297000000000001\n",
      "Cross-validating with dropout_prob 0.2\n",
      "\t\ttraining fold 0 with dropout_prob 0.2: accuracy=0.83225\n",
      "\t\ttraining fold 1 with dropout_prob 0.2: accuracy=0.837\n",
      "\t\ttraining fold 2 with dropout_prob 0.2: accuracy=0.8365\n",
      "\t\ttraining fold 3 with dropout_prob 0.2: accuracy=0.838\n",
      "\t\ttraining fold 4 with dropout_prob 0.2: accuracy=0.82375\n",
      "\tAverage accuracy of 0.8335000000000001\n",
      "Cross-validating with dropout_prob 0.30000000000000004\n",
      "\t\ttraining fold 0 with dropout_prob 0.30000000000000004: accuracy=0.83475\n",
      "\t\ttraining fold 1 with dropout_prob 0.30000000000000004: accuracy=0.827\n",
      "\t\ttraining fold 2 with dropout_prob 0.30000000000000004: accuracy=0.8375\n",
      "\t\ttraining fold 3 with dropout_prob 0.30000000000000004: accuracy=0.83775\n",
      "\t\ttraining fold 4 with dropout_prob 0.30000000000000004: accuracy=0.83975\n",
      "\tAverage accuracy of 0.83535\n",
      "Cross-validating with dropout_prob 0.4\n",
      "\t\ttraining fold 0 with dropout_prob 0.4: accuracy=0.845\n",
      "\t\ttraining fold 1 with dropout_prob 0.4: accuracy=0.83325\n",
      "\t\ttraining fold 2 with dropout_prob 0.4: accuracy=0.838\n",
      "\t\ttraining fold 3 with dropout_prob 0.4: accuracy=0.84325\n",
      "\t\ttraining fold 4 with dropout_prob 0.4: accuracy=0.83075\n",
      "\tAverage accuracy of 0.83805\n",
      "Cross-validating with dropout_prob 0.5\n",
      "\t\ttraining fold 0 with dropout_prob 0.5: accuracy=0.83525\n",
      "\t\ttraining fold 1 with dropout_prob 0.5: accuracy=0.84125\n",
      "\t\ttraining fold 2 with dropout_prob 0.5: accuracy=0.8435\n",
      "\t\ttraining fold 3 with dropout_prob 0.5: accuracy=0.84075\n",
      "\t\ttraining fold 4 with dropout_prob 0.5: accuracy=0.83525\n",
      "\tAverage accuracy of 0.8392\n",
      "Cross-validating with dropout_prob 0.6000000000000001\n",
      "\t\ttraining fold 0 with dropout_prob 0.6000000000000001: accuracy=0.84125\n",
      "\t\ttraining fold 1 with dropout_prob 0.6000000000000001: accuracy=0.84325\n",
      "\t\ttraining fold 2 with dropout_prob 0.6000000000000001: accuracy=0.84675\n",
      "\t\ttraining fold 3 with dropout_prob 0.6000000000000001: accuracy=0.849\n",
      "\t\ttraining fold 4 with dropout_prob 0.6000000000000001: accuracy=0.843\n",
      "\tAverage accuracy of 0.84465\n",
      "Cross-validating with dropout_prob 0.7000000000000001\n",
      "\t\ttraining fold 0 with dropout_prob 0.7000000000000001: accuracy=0.84825\n",
      "\t\ttraining fold 1 with dropout_prob 0.7000000000000001: accuracy=0.848\n",
      "\t\ttraining fold 2 with dropout_prob 0.7000000000000001: accuracy=0.8535\n",
      "\t\ttraining fold 3 with dropout_prob 0.7000000000000001: accuracy=0.85275\n",
      "\t\ttraining fold 4 with dropout_prob 0.7000000000000001: accuracy=0.849\n",
      "\tAverage accuracy of 0.8503000000000001\n",
      "Cross-validating with dropout_prob 0.8\n",
      "\t\ttraining fold 0 with dropout_prob 0.8: accuracy=0.853\n",
      "\t\ttraining fold 1 with dropout_prob 0.8: accuracy=0.84725\n",
      "\t\ttraining fold 2 with dropout_prob 0.8: accuracy=0.85\n",
      "\t\ttraining fold 3 with dropout_prob 0.8: accuracy=0.85475\n",
      "\t\ttraining fold 4 with dropout_prob 0.8: accuracy=0.84325\n",
      "\tAverage accuracy of 0.8496500000000001\n",
      "Cross-validating with dropout_prob 0.9\n",
      "\t\ttraining fold 0 with dropout_prob 0.9: accuracy=0.79075\n",
      "\t\ttraining fold 1 with dropout_prob 0.9: accuracy=0.78225\n",
      "\t\ttraining fold 2 with dropout_prob 0.9: accuracy=0.79075\n",
      "\t\ttraining fold 3 with dropout_prob 0.9: accuracy=0.783\n",
      "\t\ttraining fold 4 with dropout_prob 0.9: accuracy=0.78525\n",
      "\tAverage accuracy of 0.7864\n"
     ]
    }
   ],
   "source": [
    "for p in np.linspace(0, 1, 10, endpoint=False)[1:]: \n",
    "    cross_validate(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "19000/19000 [==============================] - 7s 346us/step - loss: 0.5481 - acc: 0.7184\n",
      "Epoch 2/20\n",
      "19000/19000 [==============================] - 6s 302us/step - loss: 0.3961 - acc: 0.8442\n",
      "Epoch 3/20\n",
      "19000/19000 [==============================] - 7s 351us/step - loss: 0.3688 - acc: 0.8610\n",
      "Epoch 4/20\n",
      "19000/19000 [==============================] - 7s 343us/step - loss: 0.3463 - acc: 0.8734\n",
      "Epoch 5/20\n",
      "19000/19000 [==============================] - 6s 335us/step - loss: 0.3308 - acc: 0.8809\n",
      "Epoch 6/20\n",
      "19000/19000 [==============================] - 6s 323us/step - loss: 0.3294 - acc: 0.8821\n",
      "Epoch 7/20\n",
      "19000/19000 [==============================] - 6s 321us/step - loss: 0.3297 - acc: 0.8862\n",
      "Epoch 8/20\n",
      "19000/19000 [==============================] - 6s 323us/step - loss: 0.3284 - acc: 0.8891\n",
      "Epoch 9/20\n",
      "19000/19000 [==============================] - 6s 320us/step - loss: 0.3213 - acc: 0.8933\n",
      "Epoch 10/20\n",
      "19000/19000 [==============================] - 6s 327us/step - loss: 0.3193 - acc: 0.8981\n",
      "Epoch 11/20\n",
      "19000/19000 [==============================] - 6s 328us/step - loss: 0.3156 - acc: 0.9003\n",
      "Epoch 12/20\n",
      "19000/19000 [==============================] - 6s 329us/step - loss: 0.3124 - acc: 0.9013\n",
      "Epoch 13/20\n",
      "19000/19000 [==============================] - 6s 329us/step - loss: 0.3172 - acc: 0.9062\n",
      "Epoch 14/20\n",
      "19000/19000 [==============================] - 6s 326us/step - loss: 0.3082 - acc: 0.9082\n",
      "Epoch 15/20\n",
      "19000/19000 [==============================] - 6s 329us/step - loss: 0.3017 - acc: 0.9084\n",
      "Epoch 16/20\n",
      "19000/19000 [==============================] - 6s 330us/step - loss: 0.2985 - acc: 0.9124\n",
      "Epoch 17/20\n",
      "19000/19000 [==============================] - 6s 332us/step - loss: 0.2907 - acc: 0.9157\n",
      "Epoch 18/20\n",
      "19000/19000 [==============================] - 6s 333us/step - loss: 0.2903 - acc: 0.9188\n",
      "Epoch 19/20\n",
      "19000/19000 [==============================] - 6s 329us/step - loss: 0.2903 - acc: 0.9189\n",
      "Epoch 20/20\n",
      "19000/19000 [==============================] - 6s 329us/step - loss: 0.2768 - acc: 0.9248\n",
      "1000/1000 [==============================] - 0s 309us/step\n",
      "[0.5787719277143478, 0.857]\n"
     ]
    }
   ],
   "source": [
    "model = build_model(0.7)\n",
    "model.fit(X[:19000,:], y[:19000], batch_size=64, epochs=20)\n",
    "score = model.evaluate(X[19000:,:], y[19000:])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = np.loadtxt('test_data.txt', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[4567]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 8s 407us/step - loss: 0.5539 - acc: 0.7206\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 7s 330us/step - loss: 0.3960 - acc: 0.8460\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 7s 339us/step - loss: 0.3673 - acc: 0.8633\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 7s 342us/step - loss: 0.3468 - acc: 0.8718\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 7s 354us/step - loss: 0.3341 - acc: 0.8777\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 7s 349us/step - loss: 0.3328 - acc: 0.8827\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 7s 345us/step - loss: 0.3338 - acc: 0.8836\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 7s 337us/step - loss: 0.3277 - acc: 0.8869\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 7s 330us/step - loss: 0.3249 - acc: 0.8928\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 7s 330us/step - loss: 0.3264 - acc: 0.8929\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 7s 330us/step - loss: 0.3238 - acc: 0.8973\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 7s 327us/step - loss: 0.3167 - acc: 0.8987\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 7s 336us/step - loss: 0.3115 - acc: 0.9017\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 7s 330us/step - loss: 0.3105 - acc: 0.9044\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 7s 337us/step - loss: 0.3080 - acc: 0.9093\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 7s 333us/step - loss: 0.3020 - acc: 0.9112\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 7s 333us/step - loss: 0.3045 - acc: 0.9116\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 7s 335us/step - loss: 0.2894 - acc: 0.9130\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 7s 352us/step - loss: 0.2909 - acc: 0.9195\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 7s 338us/step - loss: 0.2916 - acc: 0.9202\n"
     ]
    }
   ],
   "source": [
    "model = build_model(0.7)\n",
    "model.fit(X, y, batch_size=64, epochs=20)\n",
    "pred_y = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_array = np.column_stack((np.linspace(1, len(pred_y),len(pred_y)),pred_y))\n",
    "import time\n",
    "t=time.localtime()\n",
    "timestamp=time.strftime('%Y%m%d_%H%M%S',t)\n",
    "filename='submission_'+timestamp+'.txt'\n",
    "np.savetxt(filename,output_array.round(),fmt='%i',delimiter=',',header='Id,Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000e+00, 1.000e+00],\n",
       "       [2.000e+00, 1.000e+00],\n",
       "       [3.000e+00, 0.000e+00],\n",
       "       ...,\n",
       "       [9.998e+03, 0.000e+00],\n",
       "       [9.999e+03, 1.000e+00],\n",
       "       [1.000e+04, 0.000e+00]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_array.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
